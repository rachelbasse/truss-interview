{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import arrow\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x] The entire CSV is in the UTF-8 character set.\n",
    "[x] The Timestamp column should be formatted in ISO-8601 format.\n",
    "[x] The Timestamp column should be assumed to be in US/Pacific time; please convert it to US/Eastern.\n",
    "[x] All ZIP codes should be formatted as 5 digits. If there are less than 5 digits, assume 0 as the prefix.\n",
    "[x] The FullName column should be converted to uppercase. There will be non-English names.\n",
    "[x] The Address column should be passed through as is, except for Unicode validation. Please note there are commas in the Address field; your CSV parsing will need to take that into account. Commas will only be present inside a quoted string.\n",
    "[x] The FooDuration and BarDuration columns are in HH:MM:SS.MS format (where MS is milliseconds); please convert them to the total number of seconds expressed in floating point format. You should not round the result.\n",
    "[x] The TotalDuration column is filled with garbage data. For each row, please replace the value of TotalDuration with the sum of FooDuration and BarDuration.\n",
    "[x] The Notes column is free form text input by end-users; please do not perform any transformations on this column. If there are invalid UTF-8 characters, please replace them with the Unicode Replacement Character.\n",
    "[x] You can assume that the input document is in UTF-8 and that any times that are missing timezone information are in US/Pacific. If a character is invalid, please replace it with the Unicode Replacement Character. If that replacement makes data invalid (for example, because it turns a date field into something unparseable), print a warning to stderr and drop the row from your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(time):\n",
    "    units = [float(v) for v in time.split(':')]\n",
    "    return sum((coeff * unit for coeff, unit in zip([3600, 60, 1], units)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_iso8601(datetime, timezone):\n",
    "    match = re.match(r'(\\d\\d?)/(\\d\\d?)/(\\d\\d?) (\\d\\d?)(.*)', datetime)\n",
    "    time = arrow.get('20{2:0>2}-{0:0>2}-{1:0>2}T{3:0>2}{4} {5}'.format(*match.groups(), 'US/Pacific'), 'YYYY-MM-DDTHH:ss:mm A ZZZ')\n",
    "    return time.to(timezone).format('YYYY-MM-DDTHH:mm:ssZZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(in_filepath, out_filepath):\n",
    "    csv.register_dialect('truss', delimiter=',', escapechar=None, quoting=csv.QUOTE_MINIMAL)\n",
    "    with open(in_filepath, mode='rt', encoding='utf-8', errors='replace') as raw, \\\n",
    "         open(out_filepath, mode='w+', encoding='utf-8', errors='ignore') as out:\n",
    "        reader = csv.DictReader(raw)\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(out, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            # Timestamp : to ISO-8601 format in US/Eastern timezone\n",
    "            try:\n",
    "                row['Timestamp'] = to_iso8601(row['Timestamp'], 'US/Eastern')\n",
    "            except AttributeError as error:\n",
    "                print('WARNING: row {0}\\ndropped while normalizing timestamp due to error:\\n{1}'.format(list(row.values()), error))\n",
    "                continue\n",
    "            # Address : no changes\n",
    "            # ZIP : limit to 5 digits, prefix with 0\n",
    "            row['ZIP'] = '{0:0>5.5}'.format(row['ZIP'])\n",
    "            # FullName : to uppercase\n",
    "            row['FullName'] = row['FullName'].upper()\n",
    "            # FooDuration, BarDuration : HH:MM:SS.MS format to seconds (float)\n",
    "            row['FooDuration'] = to_seconds(row['FooDuration'])\n",
    "            row['BarDuration'] = to_seconds(row['BarDuration'])\n",
    "            # TotalDuration : replace with sum of FooDuration and BarDuration\n",
    "            row['TotalDuration'] = row['FooDuration'] + row['BarDuration']\n",
    "            # Notes : no changes\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNormalizer(unittest.TestCase):\n",
    "\n",
    "    def to_seconds(self):\n",
    "        self.assertEqual(to_seconds('0:0:0'), 0)\n",
    "        self.assertEqual(to_seconds('0:0:1.0'), 1)\n",
    "        self.assertEqual(to_seconds('0:1:0'), 60)\n",
    "        self.assertEqual(to_seconds('1:0:0'), 3600)\n",
    "        self.assertEqual(to_seconds('0:0:32.123'), 32.123)\n",
    "        self.assertEqual(to_seconds('0:1:32.123'), 92.123)\n",
    "        self.assertEqual(to_seconds('1:0:32.123'), 3632.123)\n",
    "\n",
    "    def to_iso8601(self):\n",
    "        self.assertEqual(to_iso8601('1/1/00 1:01:01 AM'), '2000-01-01T04:01:01-4:00')\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: C:\\Users\\Rachel\\AppData\\Roaming\\jupyter\\runtime\\kernel-35fe3d62-96a4-443a-ad2c-da0a7f9404ed (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute 'C:\\Users\\Rachel\\AppData\\Roaming\\jupyter\\runtime\\kernel-35fe3d62-96a4-443a-ad2c-da0a7f9404ed'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: row ['10/2/hï¿½ 8:44:11 AM', 'The Moon', '11', 'HERE WE GO', '1:23:32.123', '1:32:33.123', 'zzsasdfa', '']\n",
      "dropped while normalizing timestamp due to error:\n",
      "'NoneType' object has no attribute 'groups'\n"
     ]
    }
   ],
   "source": [
    "#normalize(*sys.argv[1:3])\n",
    "normalize('sample-with-broken-utf8.csv', 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
